{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed6195e",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f6740",
   "metadata": {},
   "source": [
    "## Prérequis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ada035b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.env/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in ./.env/lib/python3.13/site-packages (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in ./.env/lib/python3.13/site-packages (1.8.0)\n",
      "Requirement already satisfied: matplotlib in ./.env/lib/python3.13/site-packages (3.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.env/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.env/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.env/lib/python3.13/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: scipy>=1.10.0 in ./.env/lib/python3.13/site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in ./.env/lib/python3.13/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in ./.env/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.env/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.env/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.env/lib/python3.13/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.env/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.env/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.env/lib/python3.13/site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.env/lib/python3.13/site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.env/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyyaml in ./.env/lib/python3.13/site-packages (6.0.3)\n",
      "Requirement already satisfied: h5py in ./.env/lib/python3.13/site-packages (3.15.1)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./.env/lib/python3.13/site-packages (from h5py) (2.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install pandas numpy scikit-learn matplotlib\n",
    "%pip install pyyaml h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff96b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow[and-cuda] in ./.env/lib/python3.13/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (6.33.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (3.3.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (2.4.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (0.5.4)\n",
      "Requirement already satisfied: nvidia-cublas-cu12<13.0,>=12.5.3.2 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (12.9.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12<13.0,>=12.5.82 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (12.9.79)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12<13.0,>=12.5.82 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (12.9.86)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12<13.0,>=12.5.82 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (12.9.86)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12<13.0,>=12.5.82 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (12.9.79)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.3.0.75 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (9.18.0.77)\n",
      "Requirement already satisfied: nvidia-cufft-cu12<12.0,>=11.2.3.61 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (11.4.1.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12<11.0,>=10.3.6.82 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (10.3.10.19)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12<12.0,>=11.6.3.83 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (11.7.5.82)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12<13.0,>=12.5.1.3 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (12.5.10.65)\n",
      "Requirement already satisfied: nvidia-nccl-cu12<3.0,>=2.25.1 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (2.29.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12<13.0,>=12.5.82 in ./.env/lib/python3.13/site-packages (from tensorflow[and-cuda]) (12.9.86)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.env/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2026.1.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.env/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.10)\n",
      "Requirement already satisfied: pillow in ./.env/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (12.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.env/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.env/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.1.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.env/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.45.1)\n",
      "Requirement already satisfied: rich in ./.env/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow[and-cuda]) (14.2.0)\n",
      "Requirement already satisfied: namex in ./.env/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.1.0)\n",
      "Requirement already satisfied: optree in ./.env/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./.env/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow[and-cuda]) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.env/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.env/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.env/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow[and-cuda]) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01ad92",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b86e7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 15:52:00.316060: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c081557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "parties_du_corps=[\"Bassin\",\"HancheD\",\"GenouD\",\"ChevilleD\",\"HancheG\",\"GenouG\",\"ChevilleG\",\"Colonne\",\"Thorax\",\"Cou\",\"Tete\",\"EpauleG\",\"CoudeG\",\"PoignetG\",\"EpauleD\",\"CoudeD\",\"PoignetD\"]\n",
    "path=\"./data/points\"\n",
    "SQUELETTE = [\n",
    "    (0,1),(1,2),(2,3),        # jambe droite\n",
    "    (0,4),(4,5),(5,6),        # jambe gauche\n",
    "    (0,7),(7,8),(8,9),(9,10), # colonne\n",
    "    (8,11),(11,12),(12,13),   # bras gauche\n",
    "    (8,14),(14,15),(15,16)   # bras droit\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3db0328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import des points\n",
    "points = os.listdir(path)\n",
    "points = [f for f in points if os.path.isfile(os.path.join(path, f))]\n",
    "datas=[]\n",
    "for ele in points:\n",
    "    df=pd.DataFrame(pd.read_json(os.path.join(path, ele))['instances'].str[0].str.get('keypoints').to_list())\n",
    "    df.columns=parties_du_corps\n",
    "    datas.append(df)\n",
    "del points\n",
    "del df\n",
    "del ele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad6dc8",
   "metadata": {},
   "source": [
    "### formatage des données\n",
    "Nous considérerons un jeu de données séquentielle par vidéo.\n",
    "Chaque vecteur d'entrées du modèle fera 17x3 en dimension, soit les coordonées des 17 membres enregistré.\n",
    "\n",
    "\n",
    "`in` : ${\\mathbb{R}^{3}}^{17}$\n",
    "\n",
    "On ressors une prédiction du même type, mais centré sur le bassin :\n",
    "\n",
    "`out` : ${\\mathbb{R}^{3}}^{17}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f0b5b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "def centrage_bassin(seq):\n",
    "    bass = seq[:, 0:1, :] \n",
    "    return seq-bass\n",
    "\n",
    "\n",
    "def compute_velocity(sequence):\n",
    "    vel = np.zeros_like(sequence)\n",
    "    vel[1:] = sequence[1:] - sequence[:-1]\n",
    "    return vel\n",
    "\n",
    "# formatage des données :\n",
    "fdatas = [\n",
    "    centrage_bassin(np.array([\n",
    "        np.array([np.array(df[dt][i]) for dt in df]) \n",
    "        for i in range(df.shape[0])\n",
    "    ]))\n",
    "    for df in datas\n",
    "]\n",
    "del datas\n",
    "\n",
    "PointSequence : type = type(fdatas[0])\n",
    "print(PointSequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fc7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de frames traitées : 384446\n"
     ]
    }
   ],
   "source": [
    "# calcul des statistiques\n",
    "all_pos = np.concatenate(fdatas, axis=0)\n",
    "all_pos_flat = all_pos.reshape(-1, 51)\n",
    "\n",
    "# Statistiques pour les positions\n",
    "MEAN_POS = all_pos_flat.mean(axis=0)\n",
    "STD_POS = all_pos_flat.std(axis=0) + 1e-8\n",
    "\n",
    "# de même pour les vitesses\n",
    "fdatas_vel = [compute_velocity(seq) for seq in fdatas]\n",
    "all_vel = np.concatenate(fdatas_vel, axis=0)\n",
    "all_vel_flat = all_vel.reshape(-1, 51)\n",
    "\n",
    "MEAN_VEL = all_vel_flat.mean(axis=0)\n",
    "STD_VEL = all_vel_flat.std(axis=0) + 1e-8\n",
    "\n",
    "# et pour les os\n",
    "BONE_LENGTHS = {}\n",
    "for i, j in SQUELETTE:\n",
    "    dists = np.linalg.norm(all_pos[:, i] - all_pos[:, j], axis=1)\n",
    "    BONE_LENGTHS[(i, j)] = np.mean(dists)\n",
    "\n",
    "print(f\"frames traitées : {len(all_pos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f165e19",
   "metadata": {},
   "source": [
    "### Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b37e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_animation(sequence, title=\"\"):\n",
    "    T, _, _ = sequence.shape\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # limites fixes\n",
    "    mins = sequence.min(axis=(0,1))\n",
    "    maxs = sequence.max(axis=(0,1))\n",
    "\n",
    "    ax.set_xlim(mins[0], maxs[0])\n",
    "    ax.set_ylim(mins[1], maxs[1])\n",
    "    ax.set_zlim(mins[2], maxs[2])\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "\n",
    "    pts0 = sequence[0]\n",
    "\n",
    "    points = ax.scatter(\n",
    "        pts0[:,0], pts0[:,1], pts0[:,2],\n",
    "        c=\"red\", s=40\n",
    "    )\n",
    "\n",
    "    lines = []\n",
    "    for i, j in SQUELETTE:\n",
    "        line, = ax.plot(\n",
    "            [pts0[i,0], pts0[j,0]],\n",
    "            [pts0[i,1], pts0[j,1]],\n",
    "            [pts0[i,2], pts0[j,2]],\n",
    "            c=\"black\"\n",
    "        )\n",
    "        lines.append(line)\n",
    "\n",
    "    def update(frame):\n",
    "        pts = sequence[frame]\n",
    "\n",
    "        points._offsets3d = (pts[:,0], pts[:,1], pts[:,2])\n",
    "\n",
    "        for line, (i, j) in zip(lines, SQUELETTE):\n",
    "            line.set_data([pts[i,0], pts[j,0]],\n",
    "                          [pts[i,1], pts[j,1]])\n",
    "            line.set_3d_properties([pts[i,2], pts[j,2]])\n",
    "\n",
    "        return [points] + lines\n",
    "\n",
    "    return FuncAnimation(\n",
    "        fig,\n",
    "        update,\n",
    "        frames=T,\n",
    "        interval=33,\n",
    "        blit=False\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae2fe7",
   "metadata": {},
   "source": [
    "## Premier Jet\n",
    "\n",
    "Nous allons tenté d'utiliser un [LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a56533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 30\n",
    "\n",
    "lstm_simple = Sequential([\n",
    "    Input((WINDOW_SIZE,51)),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(128),\n",
    "    Dense(51)\n",
    "])\n",
    "\n",
    "lstm_simple.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe370306",
   "metadata": {},
   "source": [
    "Nous faison rentrer dans notre modèle les 30 dernières positions connue, pour qu'il prédise la suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_data_for_lstm_simple(data: list[PointSequence], window=WINDOW_SIZE):\n",
    "    # passage sous forme de \"fenêtre\"\n",
    "    def create_sequence(seq: PointSequence):\n",
    "        x, y = [], []\n",
    "        for i in range(len(seq) - window):\n",
    "            x.append(seq[i : i + window])\n",
    "            y.append(seq[i + window])\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    X_all, Y_all = [], []\n",
    "\n",
    "    for seq in data:\n",
    "        X, Y = create_sequence(seq)\n",
    "        X_all.append(X)\n",
    "        Y_all.append(Y)\n",
    "\n",
    "    X_all = np.concatenate(X_all)\n",
    "    Y_all = np.concatenate(Y_all)\n",
    "\n",
    "    # reshape (17,3) -> 51\n",
    "    X_all = X_all.reshape(X_all.shape[0], X_all.shape[1], -1)\n",
    "    Y_all = Y_all.reshape(Y_all.shape[0], -1)\n",
    "    # normalization\n",
    "    EPSILON = 1e-8\n",
    "    mean = X_all.mean(axis=(0, 1))\n",
    "    std = X_all.std(axis=(0, 1)) + EPSILON\n",
    "\n",
    "    X_all = (X_all - mean) / std\n",
    "    Y_all = (Y_all - mean) / std\n",
    "\n",
    "    return X_all, Y_all, mean, std\n",
    "\n",
    "\n",
    "def inverse_lstm_output(pred_seq, mean, std):\n",
    "    pred_seq = np.array(pred_seq)\n",
    "\n",
    "    # 2D\n",
    "    if pred_seq.ndim == 3 and pred_seq.shape[1:] == (17,3):\n",
    "        T = pred_seq.shape[0]\n",
    "        pred_seq = pred_seq.reshape(T, 51)\n",
    "    \n",
    "    # reshape mean et std\n",
    "    mean_flat = mean.reshape(1, 51)\n",
    "    std_flat = std.reshape(1, 51)\n",
    "\n",
    "    # dénormalisation\n",
    "    pred_seq = pred_seq * std_flat + mean_flat\n",
    "\n",
    "    # -> (T,17,3)\n",
    "    pred_seq = pred_seq.reshape(pred_seq.shape[0], 17, 3)\n",
    "\n",
    "    return pred_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6201d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrainement du modèle\n",
    "train, test= train_test_split(fdatas[:150])\n",
    "\n",
    "X, Y, _, _ = make_data_for_lstm_simple(train)\n",
    "\n",
    "lstm_simple.fit(X, Y, epochs=20, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "X_t, Y_t, mean_t, std_t = make_data_for_lstm_simple(test)\n",
    "mean_mse = 0\n",
    "Y_pred = lstm_simple.predict(X_t)\n",
    "for (y_t, y_p) in zip(Y_t, Y_pred):\n",
    "    mean_mse += mean_squared_error(y_t, y_p)\n",
    "mean_mse /= len(Y_pred)\n",
    "\n",
    "print(f\"mean mse : {mean_mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca35a195",
   "metadata": {},
   "source": [
    "Comparaison des prédictions avec les vraies valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e69914",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim1 = plot_animation(test[0][30:150], title=\"True\")\n",
    "anim2 = plot_animation(inverse_lstm_output(Y_pred, mean_t, std_t)[0:120], title=\"Pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea81860",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim1.to_jshtml()+anim2.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0920615",
   "metadata": {},
   "source": [
    "passage en auto régression  \n",
    "le modèle s'appuie sur ses dernières valeurs prédit pour en prédire de nouvelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b3339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def auto_pred(model, input, nbframe):\n",
    "    window = input.copy()\n",
    "    pred = []\n",
    "\n",
    "    for _ in range(nbframe):\n",
    "        y = model.predict(window[None], verbose=0)\n",
    "\n",
    "        pred.append(y)\n",
    "\n",
    "        window = np.vstack([window[1:], y])\n",
    "    \n",
    "    return np.array(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c991599",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Y_t[0:WINDOW_SIZE]\n",
    "Y_pred = auto_pred(lstm_simple, input, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_seq = inverse_lstm_output(Y_pred, mean_t, std_t)\n",
    "anim = plot_animation(Y_pred_seq)\n",
    "HTML(anim.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a351916",
   "metadata": {},
   "source": [
    "Le résultat n'est pas très bon...\n",
    "\n",
    "Identifions les différents problèmes :\n",
    "- le modèle ne \"sait\" pas que les os ont une taille fixe.\n",
    "- les erreurs s'accumules avec le temps\n",
    "- au lieu de prédire 1 frame à la fois, nous ferions mieux d'entrainer le modèle à prédire plusieur frames à la fois\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sauvegrade le modèle :\n",
    "lstm_simple.save('./models/lstm_simple.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2507ebc",
   "metadata": {},
   "source": [
    "## 2ème jet :\n",
    "Nous allons prendre en entré/sortie la vitesse, au lieu de la position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_position(\n",
    "    vel_seq: PointSequence, star_pos: np.ndarray, bassin_en_zero=True\n",
    ") -> PointSequence:\n",
    "    T = vel_seq.shape[0]\n",
    "    poses = np.zeros((T, 17, 3))\n",
    "\n",
    "    poses[0] = star_pos + vel_seq[0]\n",
    "\n",
    "    if bassin_en_zero:\n",
    "        poses[0, 0] = 0\n",
    "        \n",
    "    for t in range(1, T):\n",
    "        poses[t] = poses[t - 1] + vel_seq[t]\n",
    "\n",
    "        if bassin_en_zero:\n",
    "            poses[t, 0] = 0\n",
    "    return poses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f875d1",
   "metadata": {},
   "source": [
    "Nous prédirons aussi plusieurs frames à l'avance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89856b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 10\n",
    "WINDOW_SIZE = 30\n",
    "NB_FEATURES = len(parties_du_corps)*3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c72ee01",
   "metadata": {},
   "source": [
    "Changeons aussi l'architectuer du modèle, afin d'avoir une architecture plus pertinante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4cf993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D,\n",
    "    LSTM,\n",
    "    Dense,\n",
    "    Input,\n",
    "    BatchNormalization,\n",
    "    Dropout,\n",
    "    Reshape,\n",
    ")\n",
    "\n",
    "def build_conv_lstm(window_size=WINDOW_SIZE, n_features=NB_FEATURES, horizon=HORIZON):\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Input((window_size, n_features)),\n",
    "            Conv1D(128, 5, padding=\"same\", activation=\"relu\"),\n",
    "            BatchNormalization(),\n",
    "            Conv1D(128, 3, padding=\"same\", activation=\"relu\"),\n",
    "            BatchNormalization(),\n",
    "            LSTM(128),\n",
    "            Dropout(0.3),\n",
    "            Dense(horizon * n_features),\n",
    "            Reshape((horizon, n_features)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2585d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_for_conv_lstm(data: list[PointSequence], window=WINDOW_SIZE, horizon=HORIZON):\n",
    "    X_all, Y_all = [], []\n",
    "\n",
    "    for seq in data:\n",
    "        for i in range(len(seq) - window - horizon):\n",
    "            X_all.append(seq[i:i+window])\n",
    "            Y_all.append(seq[i + window : i + window + horizon])\n",
    "\n",
    "    X_all = np.array(X_all)\n",
    "    Y_all = np.array(Y_all)\n",
    "\n",
    "    X_all = X_all.reshape(X_all.shape[0], window, -1)\n",
    "    Y_all = Y_all.reshape(Y_all.shape[0], horizon, -1)\n",
    "\n",
    "    # Normalisation\n",
    "    EPSILON = 1e-8\n",
    "    mean = X_all.mean(axis=(0,1))\n",
    "    std = (X_all.std(axis=(0,1))) + EPSILON\n",
    "\n",
    "    X_all = (X_all - mean) / std\n",
    "    Y_all = (Y_all - mean) / std\n",
    "\n",
    "    return X_all, Y_all, mean, std\n",
    "\n",
    "\n",
    "def inverse_conv_lstm_output(pred, mean, std):\n",
    "    pred = pred*std+mean\n",
    "    return pred.reshape(pred.shape[0], HORIZON, 17,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2232f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on prend donc les vitesses\n",
    "\n",
    "fdatas_vel = [compute_velocity(centrage_bassin(d)) for d in fdatas]\n",
    "train, test = train_test_split(fdatas_vel[:150])\n",
    "\n",
    "X_train, Y_train, mean, std = make_data_for_conv_lstm(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafda0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lstm = build_conv_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38488a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lstm.fit(X_train, Y_train, epochs=20, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_pred_horizon(model, input, nb_frame):\n",
    "    window = input.copy()\n",
    "    preds = []\n",
    "\n",
    "    while len(preds) < nb_frame:\n",
    "        y = model.predict(window[None], verbose=0)[0]\n",
    "        preds.extend(y)\n",
    "\n",
    "        window = np.vstack([window[HORIZON:], y])\n",
    "\n",
    "    return np.array(preds[:nb_frame])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123365fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INDEX = 1\n",
    "\n",
    "input = test[TEST_INDEX][:WINDOW_SIZE]\n",
    "input = input.reshape(WINDOW_SIZE, -1)\n",
    "input = (input - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d3b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_pred = auto_pred_horizon(conv_lstm, input, 120)\n",
    "V_pred = V_pred.reshape(120, 17, 3)\n",
    "\n",
    "V_true = test[TEST_INDEX][30:150]\n",
    "\n",
    "P0 = test[TEST_INDEX][WINDOW_SIZE - 1]\n",
    "P0_true = centrage_bassin(fdatas[TEST_INDEX][WINDOW_SIZE - 1][None])[0]\n",
    "\n",
    "P_pred = compute_position(V_pred, P0)\n",
    "P_true = compute_position(V_true, P0_true)\n",
    "\n",
    "\n",
    "anim_true = plot_animation(P_true, title=\"true\")\n",
    "anim_pred = plot_animation(P_pred, title=\"pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bcb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim_true.to_jshtml()+anim_pred.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552881e",
   "metadata": {},
   "source": [
    "Le modèle est encore moins bon, nous allons donc faire en sorte de passer la vitesse + la position, afin d'avoir une loss qui prend en compte la distance entre les points, pour voir si celle-ci est réaliste (vis à vis des os)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892046bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sauvegrade le modèle :\n",
    "conv_lstm.save('./models/conv_lstm.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79784132",
   "metadata": {},
   "source": [
    "\n",
    "## 3ème jet \n",
    "\n",
    "Nous allons prendre un jeu de donner qui garde à la fois la vitesse et la position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db915cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 10\n",
    "WINDOW_SIZE = 30\n",
    "NB_FEATURES = len(parties_du_corps)*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bone_length_loss(skeleton):\n",
    "    def loss(y_true, y_pred):\n",
    "\n",
    "        y_true = tf.reshape(y_true, (-1, tf.shape(y_true)[1], 17, 3))\n",
    "        y_pred = tf.reshape(y_pred, (-1, tf.shape(y_pred)[1], 17, 3))\n",
    "\n",
    "        bone_loss = 0.0\n",
    "\n",
    "        for i, j in skeleton:\n",
    "            true_len = tf.norm(\n",
    "                y_true[:, :, i] - y_true[:, :, j],\n",
    "                axis=-1\n",
    "            )\n",
    "            pred_len = tf.norm(\n",
    "                y_pred[:, :, i] - y_pred[:, :, j],\n",
    "                axis=-1\n",
    "            )\n",
    "            bone_loss += tf.reduce_mean(tf.square(pred_len - true_len))\n",
    "\n",
    "        return bone_loss / len(skeleton)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def smooth_vel_loss(horizon=HORIZON):\n",
    "    def loss(_y_true, y_pred):\n",
    "        yp = tf.reshape(y_pred, (-1, horizon, 17, 3))\n",
    "        vel = yp[:,1:] - yp[:,:-1]\n",
    "        return tf.reduce_mean(tf.square(vel))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def total_loss(skeleton, base_loss = tf.losses.mse, bone_loss_w= 0.05, smooth_loss_w= 0.01, horizon=HORIZON):\n",
    "    bone_loss = bone_length_loss(skeleton)\n",
    "    smooth_loss = smooth_vel_loss(horizon=horizon)\n",
    "    def loss(y_true, y_pred):\n",
    "        return base_loss(y_true, y_pred) + bone_loss_w * bone_loss(y_true, y_pred) + smooth_loss_w* smooth_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D,\n",
    "    LSTM,\n",
    "    Dense,\n",
    "    Input,\n",
    "    BatchNormalization,\n",
    "    RepeatVector\n",
    ")\n",
    "from tensorflow.keras.callbacks import (EarlyStopping,ReduceLROnPlateau)\n",
    "\n",
    "def build_conv_pos_vel(window_size=WINDOW_SIZE, n_features=NB_FEATURES, horizon=HORIZON, bone_loss_weight = 0.01):\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Input((window_size, n_features)),\n",
    "\n",
    "            Conv1D(128, 5),\n",
    "            BatchNormalization(),\n",
    "            Conv1D(128, 3),\n",
    "            BatchNormalization(),\n",
    "\n",
    "            LSTM(256),\n",
    "\n",
    "            RepeatVector(horizon),\n",
    "            LSTM(256, return_sequences=True),\n",
    "\n",
    "            Dense(n_features//2),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(patience=5, factor=0.5)\n",
    "    ]\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=total_loss(SQUELETTE, bone_loss_w=bone_loss_weight))\n",
    "    return (model, callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e036b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centrage_bassin(seq: PointSequence)->PointSequence:\n",
    "    bass = seq[:, 0:1, :] \n",
    "    return seq-bass\n",
    "\n",
    "\n",
    "def make_data_for_pos_vel(data_pos: list[PointSequence], window=WINDOW_SIZE, horizon=HORIZON,stats=None):\n",
    "    X_all, Y_all = [],[]\n",
    "\n",
    "    for pos_seq in data_pos:\n",
    "        #centrage bassin\n",
    "        pos_seq = centrage_bassin(pos_seq)\n",
    "        # calcule de la vitesse\n",
    "        vel_seq = np.zeros_like(pos_seq)\n",
    "        vel_seq[1:] = pos_seq[1:] - pos_seq[:-1]\n",
    "        \n",
    "        # concatenation\n",
    "        pos_vel = np.concatenate([pos_seq, vel_seq], axis=-1) \n",
    "        \n",
    "        #création de la fenêtre\n",
    "        for i in range(len(pos_vel) - window - horizon):\n",
    "            X_all.append(pos_vel[i : i + window])\n",
    "            Y_all.append(pos_seq[i + window : i + window + horizon, :])\n",
    "\n",
    "    X_all = np.array(X_all).reshape(len(X_all), window, -1)\n",
    "    Y_all = np.array(Y_all).reshape(len(Y_all), horizon, -1)\n",
    "\n",
    "    #normalisation\n",
    "    EPSILON = 1e-8\n",
    "    if stats is None:\n",
    "        # calcules des stats si en train\n",
    "        mean_x = X_all.mean(axis=(0, 1))\n",
    "        std_x = X_all.std(axis=(0, 1)) + EPSILON\n",
    "\n",
    "        mean_y = Y_all.mean(axis=(0, 1))\n",
    "        std_y  = Y_all.std(axis=(0, 1)) + EPSILON\n",
    "\n",
    "    else:\n",
    "        # Re-utilisation des stats fournies si en test\n",
    "        mean_x, std_x, mean_y, std_y = stats\n",
    "\n",
    "    X_norm = (X_all - mean_x) / std_x\n",
    "    Y_norm = (Y_all - mean_y) / std_y\n",
    "\n",
    "    return X_norm, Y_norm, (mean_x, std_x, mean_y, std_y)\n",
    "\n",
    "def inverse_pos_vel_output(pred_norm, stats):\n",
    "    _, _, mean_y, std_y = stats\n",
    "\n",
    "    pred = np.array(pred_norm)\n",
    "\n",
    "    if pred.ndim == 3:\n",
    "        B, H, F = pred.shape\n",
    "        pred = pred.reshape(B * H, F)\n",
    "    elif pred.ndim == 2:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Format inattendu pour pred_norm\")\n",
    "\n",
    "    # dénormalisation pos\n",
    "    pred = pred * std_y + mean_y\n",
    "\n",
    "    # reshape en squelette\n",
    "    pred = pred.reshape(pred.shape[0], 17, 3)\n",
    "\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(fdatas[0:100])\n",
    "X_train, Y_train, stats = make_data_for_pos_vel(train)\n",
    "print(\"X mean abs:\", np.mean(np.abs(X_train)))\n",
    "print(\"Y mean abs:\", np.mean(np.abs(Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b55d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test,_ = make_data_for_pos_vel(test, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e631847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pos_vel,callbacks = build_conv_pos_vel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pos_vel.fit(X_train, Y_train, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=20, \n",
    "          batch_size=64,\n",
    "          callbacks = callbacks\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da452974",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_WINDOW = 50\n",
    "TRAIN_PERCENTAGE = 0.70\n",
    "EPOCHS_PER_WINDOW = 5\n",
    "# training \n",
    "i = 0\n",
    "while(i*TRAINING_WINDOW < len(fdatas) * TRAIN_PERCENTAGE):\n",
    "    i+=1\n",
    "    train, test = train_test_split(fdatas[(i-1)*TRAINING_WINDOW:i*TRAINING_WINDOW])\n",
    "    X_train, Y_train, stats = make_data_for_pos_vel(train)\n",
    "    X_test, Y_test,_ = make_data_for_pos_vel(test, stats=stats)\n",
    "    del train\n",
    "    del test\n",
    "    model_pos_vel.fit(X_train, Y_train, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=EPOCHS_PER_WINDOW, \n",
    "          batch_size=64)\n",
    "    del X_train\n",
    "    del Y_train\n",
    "    del stats\n",
    "    del X_test\n",
    "    del Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8521b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_pred_pos_vel(model, seq_pos, stats, nb_frames,\n",
    "                      window=WINDOW_SIZE, horizon=HORIZON):\n",
    "\n",
    "    mean_x, std_x, _, _ = stats\n",
    "\n",
    "    # --- préparation fenêtre initiale ---\n",
    "    seq_pos = centrage_bassin(seq_pos)\n",
    "\n",
    "    vel = np.zeros_like(seq_pos)\n",
    "    vel[1:] = seq_pos[1:] - seq_pos[:-1]\n",
    "\n",
    "    pos_vel = np.concatenate([seq_pos, vel], axis=-1)\n",
    "\n",
    "    window_data = pos_vel[:window]        # (window,17,6)\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    while len(preds) < nb_frames:\n",
    "        # normalisation\n",
    "        X = window_data.reshape(1, window, -1)\n",
    "        X = (X - mean_x) / std_x\n",
    "\n",
    "        # prédiction horizon (normalisée)\n",
    "        Y_norm = model.predict(X, verbose=0)[0]   # (horizon,51)\n",
    "\n",
    "        # inverse normalisation positions\n",
    "        Y = inverse_pos_vel_output(Y_norm, stats)   # (horizon,17,3)\n",
    "\n",
    "        # on ajoute au résultat\n",
    "        for p in Y:\n",
    "            preds.append(p)\n",
    "\n",
    "        # --- mise à jour fenêtre ---\n",
    "        # reconstruire pos+vel à partir des nouvelles positions\n",
    "        last_pos = window_data[-1, :, :3]\n",
    "\n",
    "        new_vel = Y - np.vstack([last_pos[None], Y[:-1]])\n",
    "        new_pos_vel = np.concatenate([Y, new_vel], axis=-1)\n",
    "\n",
    "        window_data = np.vstack([window_data[horizon:], new_pos_vel])\n",
    "\n",
    "    return np.array(preds[:nb_frames])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b68608",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INDEX = -1\n",
    "NB_FRAMES = 120\n",
    "\n",
    "seq = fdatas[TEST_INDEX]\n",
    "\n",
    "train, _ = train_test_split(fdatas[0:100])\n",
    "_, _, stats = make_data_for_pos_vel(train)\n",
    "\n",
    "# prédiction longue\n",
    "P_pred = auto_pred_pos_vel(\n",
    "    model_pos_vel,\n",
    "    seq_pos=seq,\n",
    "    stats=stats,\n",
    "    nb_frames=NB_FRAMES\n",
    ")\n",
    "\n",
    "P_true = centrage_bassin(seq)[WINDOW_SIZE:WINDOW_SIZE+NB_FRAMES]\n",
    "\n",
    "anim_true = plot_animation(P_true, \"true\")\n",
    "anim_pred = plot_animation(P_pred, \"pred\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e38fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim_true.to_jshtml() + anim_pred.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053580b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sauvegrade le modèle :\n",
    "model_pos_vel.save('./models/model_pos_vel.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
